# 最終提案 06/24 前定稿

###### tags: `Hakathon`

**[評分 ppt](https://drive.google.com/drive/folders/1wlSvfnbeKFiT1sr7TwhLvTuxRXI6HEdY)**

**提案包含內容**
- 組名、隊員簡介
- 作品名稱
- 主題類型
- 預計使用之資料
- 作品構想之圖文說明
- 參考資料

### 組名、隊員資料

- 組名：天氣 Hackthon 沙士比亞
- 隊員資料：

我們是一群來自不同系所並且喜歡嘗試新事物的一群熱血份子。

| 姓名           | 學校系所                   | 暱稱                   | 專長 |
| -------------- | -------------------------- | ---------------------- | ---- |
| 葉霈恩（組長） | 中央大學大氣系三年級       | Deadline Superman      |  Python, 簡報製作     |
| 林群賀 [[GitHub]](https://github.com/1chooo)        | 中央大學大氣系三年級       |  拖延大將軍             |  Python, Web Dev, LINE BOT    |
| 黃品誠         | 中央大學物理學系三年級     | 大盲人          |Python, Discord BOT, 碳足跡熱點分析|
| 林源煜         | 中央大學大氣系四年級       |  AI 小菜雞           |  Python API 開發，機器學習   |
| 周姿吟         | 中央大學數學系計資組三年級 | Phd of procrastination |  Matlab, LaTex, 影像處理    |


### 作品名稱
蛤！你怪獸怎麼一直變大（可重新命名）

### 主題類型（可提及跨域成份）
將永續概念結合機器學習或圖像辨識，以提供碳追蹤的系統，最後實作在大家日常生活中常使用的通訊軟體 - LINE。我們秉持著與資訊工程結合的開源精神並且結合共筆概念管理團隊組織運作，像是個小型新創的超級新星。
- 我們的 HackMd 管理: [Weather Shakespeare](https://hackmd.io/@1chooo/HkAes8w8h)
- 我們的 GitHub: [Weather Shakespeare](https://github.com/Weather-Shakespeare)
- 我們的介紹網站: [Weather Shakespeare](https://weather-shakespeare.github.io/)


### 預計使用之資料

- 回收物照片
- 我們自己拍攝的照片，需要針對類別標籤拍攝不同照片（詳見標籤類別）
- 爬蟲網路上可使用的圖片
- 影像識別技術或者影像識別結合機器學習應用的技術

#### 標籤類別

可能要量化我們多少訓練資料集（訓練集與測試集）

（可能會依據「預期效益」內容新增回收物種類權重）

| 回收物種類 |           預期回收物標籤種類           |
|:----------:|:--------------------------------------:|
|   寶特瓶   | 正面、反面、頂部、底部、有瓶蓋、無瓶蓋、有壓扁、無壓扁 |
|   鋁箔包   | 正面、反面、頂部、底部、有壓扁、無壓扁 |
|   紙杯、紙碗   | 正面、反面、頂部、底部、有壓扁、無壓扁 |


### 作品構想之圖文說明

#### 緣起
在日常生活中，沒有落實回收可能對環境造成衝擊與汙染。相反地，回收並再製的產品相對由原料直接製成，可以減少大量能源消耗與製造的碳排。但身邊許多人時常為了方便沒有確實落實資源回收，從而導致產生額外的碳排與汙染。為了改善這種情況，我們設計了一個 Line bot，使用者可以拍下自身落實回收的照片，經過系統辨識後集點並養怪獸，鼓勵使用者確實做好垃圾分類，並讓使用者了解落實回收可以帶來的節約能源效益。


#### 預期效益 
(NCTU 鍾佩樺 2013)
一般容器的生命週期包含原料、製程、使用、回收、再利用及廢棄等六個階段，下文所示的減碳與環境永續效益評估，主要分析廢棄物在未回收與回收一次的情況下，完整生命週期所產生之碳排與環境危害之差異值。而廢棄物的減碳與環境永續效益，主要可分為四種，其分別為人類健康（Human health , HH）、生態品質（Ecosystem quality , EQ）、氣候改變（Climate change , CC）和資源（Resources , RE），以下分別為這三種廢棄物的回收效益。

1. 玻璃
    玻璃容器一次回收法生命週期評估結果及效益為減碳效益約有 1.63x108 公噸eCO2，而其他永續環境效益如人類健康1.67x102 DALY、生態品質 3.32x107 PDF*m2*yr 和資源 2.82x109 MJ。
2. 塑膠(PE/PP)
    容器進行焚化處理衝擊僅低於製成容器衝擊 0.83 kg eCO2，專案中說明焚燒所造成的衝擊不小，其中焚燒佔 95%而掩埋 5%（環保署統計年報，101 年）。由表中我們也可看出造成最大衝擊的為製成 PE/PP 容器過程，目前每年回收塑膠的減碳效益約為2.69x108 公噸 eCO2。
3. 紙類
    目前台灣回收紙類的減碳效益為 8.44x106 公噸 eCO2，而其他永續環境效益如HH有 8.28 DALY、EQ4.52x106 PDF*m2*yr 和 RE2.62x108 MJ。
4. 金屬


目前台灣的可回收垃圾回收率約為(未知)，與理想中的目標仍有一些差距，我們期望透過我們所設計的 Line Bot 小遊戲提升使用者進行資源回收的誘因，將可回收垃圾回收率提升為()，以達到淨零排放與環境永續的終極目標。

另外，通過回收日常生活的廢棄物也能夠刺激綠色經濟的發展

#### 產品預計使用流程（模擬流程）
1. 使用者拍下回收物的照片並且回傳至 LINE BOT 聊天室
2. 後臺透過影像識別模型（我們會預先訓練）辨識回收物
3. 針對不同的回收物有不同的集點與怪獸加分機制（詳見實作方法 - 遊戲規則實作）
4. 整合回收減低碳排與碳足跡相關資訊

#### 實作方法

##### 開發流程
1. 到便利商店、量販店、回收廠進行拍攝和通過爬蟲收集準備訓練的照片
2. 將照片歸檔分類並進行標籤處理（詳見**標籤類別**）
3. 將照片檔以 7:2:1 的比例歸類為訓練集、驗證集和測試集
4. 設計神經網絡模型並進行訓練
5. 訓練完成後將模型輸出
6. 開發 Line 聊天機器人，並將神經網絡模型合併入 Line Bot 當中

##### 影像辨識部分

1. 獲取日常生活中常見廢棄物的照片，並進行標籤化分類
2. 設計辨識廢棄物照片的分類器
3. 將圖片輸入分類器進行訓練
4. 持續優化模型訓練結果
5. 將完成訓練的模型輸出並部署
6. 持續性監控模型的效能，並在必要時重新訓練模型

![](https://hackmd.io/_uploads/B1wSqGN_3.png)


##### LINE BOT 實作部分
1. 利用 Line 的 Python Flask, LINE SDK Package 開發我們的 LINE BOT 產品
2. 通過 Line 提供的開發者界面設計聊天機器人的 UI
3. 將 Line Bot 和圖像辨識模型串接（開發可串接模型用之 API）
4. 實作會員卡功能

![](https://hackmd.io/_uploads/SJ4I9zV_n.jpg)

##### 遊戲規則實作 (Ho)

`補充遊戲規則的圖`

**回收機制、得分計算**
|       回收物       | 得分  | 回收物數量累積           | 得分 | 連續回收天數           | 得分 |
| :----------------: | :---: | -------------------- | ---- | ---------------------- | ---- |
| 回收一個紙杯、紙碗 |   1   | 回收物數量累積十個   | 5    | 連續回收天數累積七天   | 5    |
|   回收一個寶特瓶   |   2   | 回收物數量累積一百個 | 10   | 連續回收天數累積三十天 | 10   |
|   回收一個鋁箔包   |   3   | 回收物數量累積五百個 | 20   | 連續回收天數累積一百天 | 20   |



**成就系統算分**
|                    | 銅牌 | 銅牌 | 銀牌 | 金牌 |
|:------------------:|:----:|:----:|:----:|:----:|
|  回收物數量（個）  |  1   |  10  | 100  | 500  |
| 連續回收天數（天） |  1   |  7   |  30  | 100  |

##### 整合平台實作
`放我們會用到的資訊、方法，全台垃圾、回收處理資訊`

- 資料來源
1. 圖解生活中的碳足跡－蘇峻葦(書，資料來源待查)
2. 環保署環境開放資料平台
3. 綠色光譜媒合資訊平台

- 可整合資訊
1. 常見一次性產品的碳足跡
2. 各縣市一般廢棄物回收率
3. 公告列管材質回收率


#### 潛在問題探討

- Q: 問題描述
    - A: 起因以及，我們想到的解決方法
---
- Q: 圖片識別情況：
    - A: 因為回收物普遍會壓扁，所以可能收到的照片不具備原有的特徵
- Q: 使用者連續傳送同一張圖片 :
    - A: 利用矩陣運算判斷兩張圖的 pixel value 差異值，若差異小於設定的 tolerance, 回傳警告語給用戶
- Q: 使用者傳送同回收物但不同背景的圖片 :
    - A: 先幫用戶加分，事後以人工方式過濾，排除短時間傳送同回收物的情況；或是利用影像分割技術判斷兩張圖片的回收物相似度多少，若高度相似則回傳用戶「疑似為同個回收物」
- Q: 判斷不準確 :
    - A: 前期在資料量不太充足時，可以有個用戶確認機制。
- Q: 後續點數兌換 :
    - A:
        1. 前期先以解鎖頭貼 or 角色人物為主
        2. 後期可以和商家談合作(以會產生大量回收物的商家為主，例如手搖飲店)
        3. 或是和民營的大眾運輸談合作（如果我們可以證明回收所帶來的減少碳足跡之效益，可以把 LINEBOT 上的集點點數轉換成 搭乘大眾運輸/騎共享單車 的優惠額度，變相鼓勵民眾搭乘大眾運輸，減少其他方面的汙染來源）
- Q: 如何增加用戶使用頻率 :
    - A: 
        1. 讓使用者體會到產品服務的價值，避免出現「平台/LineBot 使用介面過度複雜」的情況，讓使用者好上手，例如：拍宣傳/使用流程短片
        2. 鼓勵用戶評論回饋，收集第一手資料有利於後續介面或功能的優化，並解決用戶所提出的問題
        3. 發展後期可以提供用戶「個人化」的體驗 (但具體的體驗可以透過市場調查 或是 內部討論)
        4. 可以設置每日打卡活動，例如：連續登入多天解成就 or 連續多天閱讀平台上的文章資訊可以另外有獎勵機制

#### 所需技術
（林源煜）
### OpenCV

#### 影像讀取與前處理

##### 通過 OpenCV 讀取 jpg 檔案

```python
img = cv.imread('files.jpg')
cv.imshow('Cats',img)
cv.waitkey(0)
```
##### 利用 matplotlib 顯示影像

```python
blank = np.zeros((500,500,3),dtype='uint8')
blank[200:300, 300:400] = 255,255,100
cv.imshow('Cyan', blank)
#2. 畫方框(畫布, 起點, 終點, 顏色, 粗度)
# 如果 thickness=-1則為填滿
cv.rectangle(blank, (0,0), (250,250), (0,255,0), thickness = 3)
cv.imshow('Green', blank)
# 3. 畫圓形(畫布, 圓心位置, 半徑radius, 顏色, 粗度)
# 如果 thickness=-1則為填滿
cv.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness = 3)
cv.imshow('Red', blank)
# 4. 畫線條(畫布, 起點, 終點, 顏色, 粗度)
cv.line(blank ,(0,0), (blank.shape[1]//2, blank.shape[0]//2), (255,255,255), thickness = 3)
cv.imshow('Red', blank)
# 5. 加入文字(畫布, 文字內容, 起點, 字體, 大小, 顏色, 粗度)
cv.putText(blank, 'This is Jimmy.', (150,225), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2)
cv.imshow('Text', blank)
# 等待圖片關閉
cv.waitKey(0)
```

##### 圖像預處理
包含模糊化、輪廓化、膨脹和侵蝕，不同的組合和處理順序有不同的效果。

```py
img = cv.imread('../Resources/Photos/cats.jpg')
# 糊糊化(blur)
# 注意 kernel size必須是奇數(odd)，kernel size越大越模糊。
# 模糊化也有許多不同的方法可以進行，讓 kernel依據需求進行運算。
blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)
cv.imshow(‘Blur Cats’, blur)
# 輪廓化(edge cascade)
# 小技巧，可以先將圖片模糊化，再進行輪廓化，可以抓到比較少雜訊。
canny = cv.Canny(blur, 125, 175)
cv.imshow(‘Canny Cats’, canny)
# 注意膨脹、侵蝕用的照片是已經輪廓化處理過。雜訊會較少。
# 膨脹 dilating
dilated = cv.dilate(canny, (7,7), iterations=3)
cv.imshow(‘Dilated’, dilated)
# 侵蝕 eroding
eroded = cv.erode(canny, (3,3), iterations=1)
cv.imshow(‘Eroded’, eroded)
cv.waitKey(0)
```

更進階的圖像處理方法：  
**Opening (侵蝕後膨脹)** 和 **Closing（膨脹後侵蝕）**

##### 圖像旋轉
```py
img = cv.imread('../Resources/Photos/cats.jpg')
# 旋轉圖片
def rotate(img, angle, rotPoint=None):
 (height,width) = img.shape[:2]
if rotPoint is None:
 rotPoint = (width//2,height//2)
 
 rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)
 dimensions = (width,height)
return cv.warpAffine(img, rotMat, dimensions)
# 輸入角度作為參數
rotated = rotate(img, -45)
cv.imshow(‘Rotated’, rotated)
rotated_rotated = rotate(img, -90)
cv.imshow(‘Rotated Rotated’, rotated_rotated)
```

##### 圖像結構
- 輪廓：沿著物件邊緣搜尋邊緣像素所形成的路徑
- 輪廓搜尋：根據二維影像搜尋影像中物件的輪廓，並以特定的資料結構儲存，紀錄輪廓的相關資料（階層式儲存）。
- 外部輪廓：影像的外緣
- 內部輪廓：若物件內包含洞，該物件在洞的邊緣所形成的輪廓

```py
img = cv.imread('../Resources/Photos/cats.jpg')
blank = np.zeros(img.shape, dtype='uint8')
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
blur = cv.GaussianBlur(gray, (5,5), cv.BORDER_DEFAULT)
canny = cv.Canny(blur, 125, 175)

contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)
# 計算總共有幾個輪廓 contours
print(f’{len(contours)} contour(s) found!’)
# 畫出當前所有的 contours
cv.drawContours(img, contours, -1, (255,0,0), 1)
cv.imshow(‘Contours Drawn on img’, img)
# 標示 contours
cv.drawContours(blank, contours, -1, (0,255,0), 1)
cv.imshow(‘Contours Drawn on blank’, blank)
cv.waitKey(0)
```

##### 特徵拮取
根據二維的數位影像拮取一維的影像特征資料（特征向量），牽涉降維度運算（如PCA）
基本的影像識別步驟：包含 Keypoint detection, feature extraction, feature matching
* Keypoint detection: 在圖片中取得感興趣的關鍵點
* Feature extraction: 針對各關鍵點提取該區域的特征
* Feature matching: 關鍵點篩選並進行匹配

- 步驟：
    - 在圖片 A 與 B 分別找出 Keypoint 
    - 依據各個 keypoint 取出其 local features
    - 兩張圖片的 local features 進行 feature matching
    - 計算各個距離最小 keypoint

- Keypoint detection
有多種 Keypoint detector 的演算法有很多，OpenCV 中有 11 種。演算法之間可以組合使用，不同的情境適合不同的 detector。以下介紹最簡單的 FAST detector。
- Fast detector
    - 原理簡單
    - 運算速度快
    - 用於偵測 corners
    - 適用於即時偵測
    - 適用於低階執行環境
    - 最被廣泛使用的偵測器

```py
detector = cv2.FeatureDetector_create("FAST")
kps = detector.detect(gray)
print(“# of keypoints: {}".format(len(kps)))
```

### 通用影像分類器
- 通過 SVM 進行分類
    - 直接找到一個決策邊界，使得類別與類別之間的距離能夠最大化
    - 通過 RBF 進行計算
- 影像特征
    - 色彩直方圖：圖像在色譜的分佈狀況
    - SIFT：偵測有可能的興趣點和拮取關鍵的描述子
    - Visual Bag of Words：將拮取的興趣點投影到128維的空間，通過K-means進行分群，形成特征集合
- 特征選取
    - Filter method: 利用特征本身的計算權重，經由特征集合挑選權重值高的特征子集合作為最後的訓練特征
    - Wrapper method: 通過最佳化演算法將能夠提升準確率的特征納入特征子集合
    - Filter + Wrapper: 先將相差甚遠的特征進行過濾，再利用Wrapper找出最佳的特征子集合

---
(Tsu)
### [OpenCV-Python——第26章：SIFT特征点提取算法](https://blog.csdn.net/yukinoai/article/details/88912586)
- SIFT 特徵 (focus 在局部特徵) 算法可以處理兩圖像之間的平移、旋轉、invariant transform 的匹配問題
- 少量的物體即可產生大量 Sift eigen vector
- improved SIFT Algorithm 可以達到 real-time
- 經此算法所找到的 Key point (我猜是 eigen value or specific pixel), 不易受光照、invariant transform、noise 等因素影響. 特徵點例如: edge point
- 算法步驟
    - **Step 1. Scale space中的極值搜索** 利用 scale-space filtering
        $$D(x,y,\sigma)=(G(x,y,k\sigma)-G(x,y,\sigma))*I(x,y)=L(x,y,k\sigma)-L(x,y,\sigma)$$
    DoG(Difference of Gaussian) 利用兩個不同的 $\sigma$ 完成 filtering. 
    $*$: convolution 
    $G(x,y,\sigma)$: 變化尺度的 Gaussian function,
    $$G=\frac{1}{2\pi\sigma^2}e^{-\frac{(x-m/2)^2+(y-n/2)^2}{2\sigma^2}}$$
    **Remark:** $m,n$ is determined by $(6\sigma+1)(6\sigma+1)$ (可以想像成是維度)(具體的需要再查); $\sigma$ 是尺度空間因子, the smaller $\sigma$ value, the less smooth of image; 大$\sigma\rightarrow$ 圖像結構, 小 $\sigma\rightarrow$ 細節紋理
    $I(x,y)$: original image
    **Key point (最能代表這個 scale 的點): 得到 DoG 之後, 將圖像中某個 pixel, 與其附近的 8 neighbor pixels 比較, 且與同 Octave 的 previous scale & next scale 的 9 個 pixels 比較. If this pixel is a local extrema, then we say this is a key point.**
    - **Step 2. 確認 key point** 利用 *Hessian matrix* 得到 eigen value $\alpha, \beta$ 分別表示圖像 x,y 方向的梯度 (詳細公式看原文). 因 DoG 會導致較強的邊緣響應點(?? 猜測是增強 edge of object), 為了移除這類的點, 需設置閾值(在原文), 將滿足條件的 key point 保留. 低對比度和邊緣的  key point 在此步驟被丟掉.
    - **Step 3. 確認梯度方向** 利用圖像的 local gradient, 給每個 key point 一個或多個方向, 以利後續根據這些方向進行 tramsform. key point 的主方向是取其 neighborhood 梯度方向峰值最大的, 輔方向則保留峰值 $>$ 主方向峰值 80% 的方向.
    So far, 圖像的 SIFT 特徵點是涵蓋三個資訊的 key point: 
        1. 位置
        2. 尺度scale
        3. 方向
    - **Step 4. 關鍵點描述** 變換梯度的表示方法, 有利呈現較大的局部變形和光照變化. 梯度由來: 在每個 key point 的 neighborhood 並選定 scale 而測量得到 圖像的 local gradient.

    - **Step 4. 關鍵點描述** 變換梯度的表示方法, 有利呈現較大的局部變形和光照變化. 梯度由來: 在每個 key point 的 neighborhood 並選定 scale 而測量得到 圖像的 local gradient.

**例子:**

```python
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread('')
img1 = img.copy()
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

sift = cv2.xfeatures2d.SIFT_create()
kp = sift.detect(gray, None) # gray: one channel

cv2.drawKeypoints(gray, kp, img)
cv2.drawKeypoints(gray, kp, img1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) #flags 有四種模式

plt.subplot(121), plt.imshow(img),
plt.title(''), plt.axis('off')
plt.subplot(122), plt.imshow(img1),
plt.title(''), plt.axis('off')
plt.show()
```

### [【python】opencv 2小時初學者教學 ｜ 影像辨識 ｜ 影像處理 ｜ 人臉辨識 ｜ 電腦視覺](https://www.youtube.com/watch?v=xjrykYpaBBM)
- 基礎指令

```python
cv.waitkKey(1000) # 等待1000毫秒才關閉, i.e. 1秒鐘; 設定讓圖片展示的時長
cv.waitkKey(0) # 直到按下鍵盤任意鍵 or 主動打叉圖片, 才會關閉圖片

# 改變圖片大小: (1)指定大小 (2)指定縮放倍數
cv2.resize(img, (300, 300)) 
cv2.resize(img, (0, 0), fx=0.5, fy=0.5) 
``` 

- 如果要檢測輪廓(edge detection), 轉成 gray scale image (no need rgb), 好處是可以減少運算量(3 channel $\to$ 1 channel) 

```python
# 檢測邊緣
canny = cv2.Canny(img, 150, 200) #設定門檻的最小最大值

# 偵測輪廓: 回傳輪廓 & 階層, 階層用不到
# 選擇偵測模式: 內輪廓 or 外輪廓 or 內外都要; 選擇近似方法: 可以壓縮水平 or 垂直方向的輪廓點
contours, hierarchy = cv2.fingContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) 
```

### [Machine Learning Model Deployment](https://www.dominodatalab.com/blog/machine-learning-model-deployment)
![](https://hackmd.io/_uploads/B10TeaWO3.png)
- **Training:**  select an algorithm, set its parameters and train it on prepared, cleaned data
- **Validation:** includes testing the model on a fresh data set and comparing the results to its initial training.
- **Deployment:** model needs to be moved into its deployed environment $\to$ the model needs to be integrated into a process $\to$ 使用模型的人員需要接受培訓，以了解如何啟動模型、訪問其數據和解釋其輸出
- **Monitoring:** The best way to monitor a model is to routinely evaluate its performance in its deployed environment. Every deployed model has the potential to degrade over time due to such issues as:
    1. Variance in deployed data. The data given to the model in deployment is not cleaned in the same manner as the training and testing data were.
    2. Changes in data integrity.
    3. Data drift. 人口統計變化、市場變動等等可能會隨時間的推移而改變
    4. Concept drift. 終端用戶對於何為正確預測的期望可能會發生變化，使得模型的預測不再具有相關性


### [Image Segmentation with Diffusion Probabilistic Models](https://arxiv.org/pdf/2112.00390.pdf)
- diffusion probabilistic method 被用於圖像生成。此論文提出了一種擴展這種模型以進行圖像分割的方法。該方法無需依賴 pre-trained backbone。將輸入圖像的信息和當前分割圖的估計結果相加，通過兩個編碼器的輸出進行合併。然後使用額外的編碼層和解碼器迭代地改進分割圖，使用擴散模型。由於擴散模型具有概率性質，因此它被應用多次，將結果合併為最終的分割圖。
-  including active contour and their deep variants, encoder-decoder architectures, and U-Nets
-  用到的 dataset: 
    1. the Cityscapes validation set 
    2. the Vaihingen building segmentation benchmark 
    3. the MoNuSeg dataset.
![](https://hackmd.io/_uploads/Hy_aPpWd3.png)

對於使用在擴散模型中的 UNet，我們進一步進行解耦。對於其編碼器，我們將其進一步拆分為 E、F、G 三部分。其中，E 負責與解碼器 D 進行連接，G 負責編碼原始圖像，F 負責編碼前一步的噪聲。

$$\epsilon_{\theta}(x_t, I, t) = D(E(F(x_t) + G(I), t), t). (17)$$


### [YOLO - object detection](https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html)

an extremely fast multi object detection algorithm (uses **CNN**)
- Step 1. Load the YOLO network
- Step 2. Create a blob (the input to the network is a so-called blob object): it has the following parameters:
    - the image to transform
    - the scale factor (1/255 to scale the pixel values to [0..1])
    - the size, here a 416x416 square image
    - the mean value (default=0)
    - the option swapBR=True (since OpenCV uses BGR)
- Step 3. Identifiy objects
- Step 4. 3 Scales for handling different sizes. The YOLO network has 3 outputs:
    - 507 (13 x 13 x 3) for large objects
    - 2028 (26 x 26 x 3) for medium objects
    - 8112 (52 x 52 x 3) for small objects
- Step 5. Detecting objects


### 參考資料
- [Chop Shop (Open Source)](https://github.com/coryl/ChopShopOpenSource/blob/master/README.md)
- [OpenCV GrabCut: Foreground Segmentation and Extraction](https://pyimagesearch.com/2020/07/27/opencv-grabcut-foreground-segmentation-and-extraction/)
- [Interactive Foreground Extraction using GrabCut Algorithm](https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html)
- [Green togo 綠色光譜廢棄物媒合平台](https://www.green-togo.tw/green-footprint.php)
- [低碳生活提案(圖解生活中的碳足跡)](https://vocus.cc/lowcarbon/home)
- [YOLO - object detection](https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html)
- [資源回收效益分析 NCTU，鍾佩樺，2013](https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html)
- [Image Segmentation with Diffusion Probabilistic Models](https://arxiv.org/pdf/2112.00390.pdf)
- [OpenCV Python 中文教學](https://github.com/grady1006/OpenCV-Python-Chinesse-Tutorials)
- [Machine Learning Model Deployment](https://www.dominodatalab.com/blog/machine-learning-model-deployment)
- [【python】opencv 2小時初學者教學 ｜ 影像辨識 ｜ 影像處理 ｜ 人臉辨識 ｜ 電腦視覺](https://www.youtube.com/watch?v=xjrykYpaBBM)
- [OpenCV-Python——第26章：SIFT特征点提取算法](https://blog.csdn.net/yukinoai/article/details/88912586)
- [圖像特徵比對(一)-取得影像的特徵點](https://chtseng.wordpress.com/2017/05/06/%E5%9C%96%E5%83%8F%E7%89%B9%E5%BE%B5%E6%AF%94%E5%B0%8D%E4%B8%80-%E5%8F%96%E5%BE%97%E5%BD%B1%E5%83%8F%E7%9A%84%E7%89%B9%E5%BE%B5%E9%BB%9E/)
- [A Generalized Image Classifier based on Feature Selection](http://rportal.lib.ntnu.edu.tw:8080/server/api/core/bitstreams/7160b71e-2ffe-4768-bd35-9dad23365c19/content)
- [Image Retrieval For Buildings and Scenic Spots](https://cv.cs.nthu.edu.tw/upload/undergraduate/9662141/index.htm)
- [[OpenCV]基礎教學筆記：影像讀取、前處理(with python)-001](https://medium.com/jimmy-wang/opencv-%E5%9F%BA%E7%A4%8E%E6%95%99%E5%AD%B8%E7%AD%86%E8%A8%98-with-python-d780f571a57a)
- [[Day 28]特徵擷取](https://ithelp.ithome.com.tw/articles/10304504?sc=iThelpR)
- [用Python實現OpenCV特徵提取與圖像檢索 | Demo](https://kknews.cc/zh-tw/code/r5394eo.html)